{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluating Empiric network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjJXqCB7J1aILQ399nnxkb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MakC-Ukr/oracle-validation-starknet/blob/master/evaluations/Evaluating_Empiric_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tzdi8tjNhkaY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su7ndSQNhqvA",
        "outputId": "fb64d0a3-745b-4f10-aa3b-0cd401dc76bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded_df = pd.read_csv(\"/content/drive/MyDrive/oracle-data-starknet/empiric-events.csv\", index_col = 0)"
      ],
      "metadata": {
        "id": "R380GyHRhrqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = loaded_df.drop('transaction_hash', axis = 1)"
      ],
      "metadata": {
        "id": "0IiuHN8niWJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df[df['key'] == \"btc/usd\"]"
      ],
      "metadata": {
        "id": "451BcFGQhu2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df[df['timestamp'] >= 1659240910][df['timestamp'] <= 1660282030]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDW6hSDth-NQ",
        "outputId": "5c002c3c-3602-4586-e8ad-495361eedfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df =df.sort_values(\"timestamp\")"
      ],
      "metadata": {
        "id": "XqKbGxlcn4AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv(\"/content/drive/MyDrive/oracle-data-starknet/empiric-BTC-31_to_12.csv\")"
      ],
      "metadata": {
        "id": "VKGGZvhlnfOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now the data for Empiric that we have is also in the same date range as for Stork (July 31 - August 12)**\n"
      ],
      "metadata": {
        "id": "XEXvSSvyk4CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/oracle-data-starknet/empiric-BTC-31_to_12.csv\")"
      ],
      "metadata": {
        "id": "sOLqm6RNtHan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['source'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhFK_Ue-ki1a",
        "outputId": "e5e68202-650c-43f6-c5c3-b5f6ad7d65e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cmt', 'gemini', 'ftx', 'cex', 'bitstamp',\n",
              "       'cryptowatch-coinbase-pro', 'cryptowatch-kraken',\n",
              "       'cryptowatch-binance', 'cryptowatch-bitfinex', 'coingecko',\n",
              "       'coinbase'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_avg_time_diff(datafr):\n",
        "  diff_ls = []\n",
        "  diff = 0\n",
        "  prev = 0\n",
        "  for ind, row in datafr.iterrows():\n",
        "    if prev == 0:\n",
        "      prev = row['timestamp']\n",
        "      continue\n",
        "    curr_diff = (row['timestamp'] - prev)\n",
        "    diff += curr_diff\n",
        "    if curr_diff > 10:\n",
        "      diff_ls.append(curr_diff)\n",
        "    prev = row['timestamp']\n",
        "\n",
        "  print(\"Median difference in seconds between two subsequent rows is :\", pd.Series(diff_ls).median())\n",
        "  return pd.Series(diff_ls)"
      ],
      "metadata": {
        "id": "C7Obz8_3okfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limiting myself only to the publisher being **Empiric** only"
      ],
      "metadata": {
        "id": "OUO4PV5AoTn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['publisher'] == \"empiric\"]"
      ],
      "metadata": {
        "id": "oyfJgZXxlPSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sr = find_avg_time_diff(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLC-MCPfoeNL",
        "outputId": "6f9cf62f-10fc-42ea-dbe8-bab91ec3f387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median difference in seconds between two subsequent rows is : 93.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_diff = {}\n",
        "time_diff[\"<1 mins\"] = len(sr[sr < 60])\n",
        "time_diff[\">5 mins\"] = len(sr[sr > 300])\n",
        "time_diff[\">6 mins\"] = len(sr[sr > 360])\n",
        "time_diff[\">7 mins\"] = len(sr[sr > 420])\n",
        "time_diff[\">8 mins\"] = len(sr[sr > 480])\n",
        "time_diff[\">9 mins\"] = len(sr[sr > 540])\n",
        "time_diff[\">10 mins\"] = len(sr[sr > 600])\n",
        "time_diff[\">20 mins\"] = len(sr[sr > 1200])\n",
        "pd.Series(time_diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsQLvGMVo9QL",
        "outputId": "638d8b01-3f30-4c0d-8960-a66fe0af2a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1 mins     2208\n",
              ">5 mins       26\n",
              ">6 mins       26\n",
              ">7 mins       20\n",
              ">8 mins        4\n",
              ">9 mins        0\n",
              ">10 mins       0\n",
              ">20 mins       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr[sr > 420]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbJq1RFIrYUS",
        "outputId": "2977490e-a3ee-482d-8d0a-400c3027721d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "323     498\n",
              "508     482\n",
              "817     457\n",
              "838     441\n",
              "1074    432\n",
              "4812    474\n",
              "4883    438\n",
              "5908    443\n",
              "6032    540\n",
              "7013    451\n",
              "7232    470\n",
              "7617    439\n",
              "7620    437\n",
              "8041    442\n",
              "8417    438\n",
              "8598    441\n",
              "9157    455\n",
              "9166    498\n",
              "9372    438\n",
              "9436    440\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The average time between two subsequent updates is 93 seconds. Much less than Stork. Moreover, for the current time range (12 days), there doesn't seem to be any outage for more than 10 mins (only singe )**"
      ],
      "metadata": {
        "id": "NJ4UNRXbqxz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The only thing that is unclear is why the timestamp difference sometimes is very minimal (like 2-3 seconds)**"
      ],
      "metadata": {
        "id": "6w6ERR8lspsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SlVmOqfKtLM8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}